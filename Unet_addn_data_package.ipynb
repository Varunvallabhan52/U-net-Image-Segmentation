{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_addn_data_package.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJRF2yBk37un",
        "colab_type": "code",
        "outputId": "a3764d85-fb57-42d9-f732-3c9d505748d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMpiUmjs8Wm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db34SN8I8axm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class train:\n",
        "  \"\"\" \n",
        "  :path_to_folder: string\n",
        "  :name_image_train: string\n",
        "  :name_mask_train: string\n",
        "  :path_to_save_model: string\n",
        "  :height: int\n",
        "  :width: int\n",
        "  :channel: int\n",
        "  :feature_factor: int\n",
        "  :number_of_layers: int\n",
        "  :batch_size: int\n",
        "  :epochs: int\n",
        "  :learning_rate: float\n",
        "  \n",
        "  This class deals with training the model. It includes the two models: 6 layered and 10 layered. The number of features can be set manually by using the feature_factor \n",
        "  and also the learning rates can be changed. The constructor is explained below.\n",
        "  \"\"\"\n",
        "  def __init__(self,path_to_folder,name_image_train,name_mask_train,path_to_save_model,\\\n",
        "               height=512,width=512,channel=1,feature_factor=64,number_of_layers=6,batch_size=2,epochs=5,learning_rate=5e-4):\n",
        "    self.img_trn=name_image_train\n",
        "    self.msk_trn=name_mask_train\n",
        "    self.feature=feature_factor\n",
        "    self.Image_height=height\n",
        "    self.Image_width=width\n",
        "    self.Image_channel=channel\n",
        "    self.number_of_layer=number_of_layers\n",
        "    self.batch=batch_size\n",
        "    self.epoch=epochs\n",
        "    self.path=path_to_folder\n",
        "    self.save_model=path_to_save_model\n",
        "    self.lr=learning_rate\n",
        "\n",
        "    \n",
        "  def load_data(self,path,name):\n",
        "    return np.load(path+'/'+name)\n",
        "\n",
        "  \n",
        "  def ten_layer(self,feature_factor=64,pretrained_weights = None):\n",
        "      '''\n",
        "      :feature_factor: int\n",
        "      :pretrained_weights: string(path to the weights/model)\n",
        "      \n",
        "      This generates the untrained 10 layered Unet model.\n",
        "      '''\n",
        "      inputs = Input((self.Image_height,self.Image_width,self.Image_channel))\n",
        "      conv1 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "      conv1 = Dropout(0.2)(conv1)\n",
        "      conv1 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "      conv1 = BatchNormalization()(conv1)\n",
        "      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "      conv2 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "\n",
        "      conv2 = Dropout(0.2)(conv2)\n",
        "      conv2 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "      conv2 = BatchNormalization()(conv2)\n",
        "      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "      conv3 = Conv2D(feature_factor*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "      conv3 = Dropout(0.2)(conv3)\n",
        "      conv3 = Conv2D(feature_factor*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "      conv3 = BatchNormalization()(conv3)\n",
        "      pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "      conv4 = Conv2D(feature_factor*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "      conv4 = Dropout(0.2)(conv4)\n",
        "      conv4 = Conv2D(feature_factor*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "      conv4 = BatchNormalization()(conv4)\n",
        "      drop4 = Dropout(0.5)(conv4)\n",
        "      pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "      conv5 = Conv2D(feature_factor*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "      conv5 = Conv2D(feature_factor*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "      conv5 = BatchNormalization()(conv5)\n",
        "      drop5 = Dropout(0.2)(conv5)\n",
        "\n",
        "      up6 = Conv2D(feature_factor*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "      merge6 = concatenate([drop4,up6], axis = 3)\n",
        "      conv6 = Conv2D(feature_factor*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "      conv6 = Dropout(0.2)(conv6)\n",
        "      conv6 = Conv2D(feature_factor*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "      conv6 = BatchNormalization()(conv6)\n",
        "\n",
        "      up7 = Conv2D(feature_factor*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "      merge7 = concatenate([conv3,up7], axis = 3)\n",
        "      conv7 = Conv2D(feature_factor*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "      conv7 = Dropout(0.2)(conv7)\n",
        "      conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "      conv7 = BatchNormalization()(conv7)\n",
        "\n",
        "      up8 = Conv2D(feature_factor*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "      merge8 = concatenate([conv2,up8], axis = 3)\n",
        "      conv8 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "      conv8 = Dropout(0.2)(conv8)\n",
        "      conv8 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "      conv8 = BatchNormalization()(conv8)\n",
        "\n",
        "      up9 = Conv2D(feature_factor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "      merge9 = concatenate([conv1,up9], axis = 3)\n",
        "      conv9 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "      conv9 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "      conv9 = BatchNormalization()(conv9)\n",
        "      conv9 = Dropout(0.2)(conv9)\n",
        "      conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "      conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "      model = Model(input = inputs, output = conv10)\n",
        "\n",
        "      model.compile(optimizer = Adam(lr = 5e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "      model.summary()\n",
        "\n",
        "\n",
        "      if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "      return model\n",
        "\n",
        "    \n",
        "  def six_layer(self,feature_factor=64,pretrained_weights = None ): \n",
        "      '''\n",
        "      :feature_factor: int\n",
        "      :pretrained_weights: string (path to the weights/model)\n",
        "      \n",
        "      This generates the untrained 6 layered Unet model. \n",
        "      '''\n",
        "      inputs = Input((self.Image_height,self.Image_width,self.Image_channel))\n",
        "      conv1 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "      conv1 = Dropout(0.2)(conv1)\n",
        "      conv1 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "      conv1 = BatchNormalization()(conv1)\n",
        "      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "      conv2 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "      #conv2 = Dropout(0.2)(conv2)\n",
        "      conv2 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "      conv2 = BatchNormalization()(conv2)\n",
        "      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "      conv3 = Conv2D(feature_factor*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "      conv3 = Dropout(0.2)(conv3)\n",
        "      conv3 = Conv2D(feature_factor*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "      conv3 = BatchNormalization()(conv3)\n",
        "\n",
        "\n",
        "      up4 = Conv2D(feature_factor*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv3))\n",
        "      merge4 = concatenate([conv2,up4],axis=3)\n",
        "      conv4 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge4)\n",
        "      #conv4 = Dropout(0.2)(conv4)\n",
        "      conv4 = Conv2D(feature_factor*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "      conv4 = BatchNormalization()(conv4)\n",
        "\n",
        "      up5 = Conv2D(feature_factor, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv4))\n",
        "      merge5 = concatenate([conv1,up5],axis=3)\n",
        "      conv5 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge5)\n",
        "      conv5 = Conv2D(feature_factor, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "      conv5 = BatchNormalization()(conv5)\n",
        "      conv5 = Dropout(0.2)(conv5)\n",
        "      conv5 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "\n",
        "      conv6 = Conv2D(1, 1, activation = 'sigmoid')(conv5)\n",
        "      model = Model(input = inputs, output = conv6)\n",
        "\n",
        "      model.compile(optimizer = Adam(lr = self.lr), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "      model.summary()\n",
        "\n",
        "      if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "      return model\n",
        "\n",
        "    \n",
        "  def compile(self):\n",
        "    '''\n",
        "    :rtype: trained model\n",
        "    \n",
        "    This function calls the model and trains it with the given dataset. \n",
        "    We first load the data then initialise the model and then create a checkpoint to \n",
        "    save the model with the best results and then train the model with the checkpoint.\n",
        "    '''\n",
        "    img_trn=self.load_data(self.path,self.img_trn)\n",
        "    msk_trn=self.load_data(self.path,self.msk_trn)\n",
        "    if self.number_of_layer==6:\n",
        "      model = self.six_layer(feature_factor=self.feature)\n",
        "    elif self.number_of_layer==10:\n",
        "      model=self.ten_layer(feature_factor=self.feature)\n",
        "    model_checkpoint = ModelCheckpoint(self.save_model, monitor='loss',verbose=1, save_best_only=True)\n",
        "    model.fit(img_trn,msk_trn,batch_size=self.batch,epochs=self.epoch,callbacks=[model_checkpoint])\n",
        "    return model\n",
        "      \n",
        "  \n",
        "  \n",
        "class test:\n",
        "    \"\"\"\n",
        "    :path_to_testdata: string\n",
        "    :path_to_outputfolder: string\n",
        "    :model: tensor object(trained model)\n",
        "    :COLOR_DICT: dictionary\n",
        "    :image_height: int\n",
        "    :image_width: int\n",
        "    :image_channel: int\n",
        "    :batch_size: int\n",
        "    \n",
        "    This class includes all the functions needed for running the model on the test dataset and saving the results. The constructor is explained below.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,path_to_testdata, path_to_outputfolder, model,COLOR_DICT,image_height=512,image_width=512,image_channel=1,batch_size=15):\n",
        "        self.COLOR_DICT=COLOR_DICT\n",
        "        self.Image_height=image_height\n",
        "        self.Image_width=image_width\n",
        "        self.Image_channel=image_channel\n",
        "        self.model=model\n",
        "        self.fetch_path=path_to_testdata\n",
        "        self.save_path=path_to_outputfolder\n",
        "        \n",
        "        self.batch=batch_size\n",
        "    \n",
        "    \n",
        "    def load_data(self,path):\n",
        "        return np.load(path)\n",
        "    \n",
        "    \n",
        "    def labelVisualize(self,num_class,color_dict,img):\n",
        "        img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "        img_out = np.zeros(img.shape + (3,))\n",
        "        for i in range(num_class):\n",
        "            img_out[img == i,:] = color_dict[i]\n",
        "        return img_out / 255.\n",
        "      \n",
        "    \n",
        "    def saveResult(self,save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "        for i,item in enumerate(npyfile):\n",
        "            img = self.labelVisualize(num_class,self.COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "            cv2.imwrite(os.path.join(save_path+'/'+\"unet_%d_predict.bmp\"%i),img*255)\n",
        "\n",
        "    \n",
        "    def execute(self):\n",
        "      '''\n",
        "      This loads the test data, runs it through the trained model and saves the outputs.\n",
        "      '''\n",
        "      imgtst=self.load_data(self.fetch_path)\n",
        "      results = self.model.predict(imgtst,batch_size=self.batch,verbose=1)\n",
        "      self.saveResult(self.save_path,results)\n",
        "      \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9xC-8OU8fDi",
        "colab_type": "code",
        "outputId": "974c4d08-82df-4288-b87e-bcf6b168626a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "constructor: train parameters\n",
        "\n",
        "path_to_folder='<path to the train folder which includes images and label>''\n",
        "name_image_train='<name of the image file .npy>'\n",
        "name_mask_train='<name of the mask file .npy>'\n",
        "path_to_save_model='<path to save the model with the name of the name of the file.hdf5>'\n",
        "height=512           #height of the image default set to 512 \n",
        "width=512            #width of the image default set to 512\n",
        "channel=1            #channels of the image default is set to 1\n",
        "feature_factor=64    #deciding factors on number of features\n",
        "number_of_layers=6   # choose between 10 and 6\n",
        "batch_size=2         # batch size for training\n",
        "epochs=5             #number of epochs for training\n",
        "learning_rate=5e-4   #learning rate for learning. default 5e-4.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train('<path to the train folder which includes images and label>',\"<name of the image file.npy>\",\"<name of the maskfile.npy>\",\\\n",
        "      \"<the path where you want to save the model and name of the model>\",image_height,image_width,image_channels,feature_factor,\n",
        "       number of layers (6 or 10),batch_size,epochs, learningrate ) <.compile> to call the main function\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "net=train(path_to_folder='drive/My Drive/GAN_seg/ADDN-master/data',name_image_train='new_img_trn.npy',\\\n",
        "          name_mask_train='new_msk_trn.npy',path_to_save_model='drive/My Drive/GAN_seg/unet.hdf5', batch_size=4,number_of_layers=10).compile()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 21:56:07.204146 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0808 21:56:07.270922 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0808 21:56:07.294000 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0808 21:56:07.322692 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0808 21:56:07.331761 140242217576320 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0808 21:56:07.366976 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0808 21:56:10.522721 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0808 21:56:10.594963 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0808 21:56:11.108160 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
            "W0808 21:56:11.613055 140242217576320 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0808 21:56:11.624428 140242217576320 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 512, 512, 64) 640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512, 512, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 256, 256, 128 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 128 147584      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 128 512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 128 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 128, 128, 256 0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 256 590080      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 256 1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64, 64, 512)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 512)  2359808     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 512)  2048        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 64, 64, 512)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 1024) 9438208     conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 1024) 4096        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 1024) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 1024) 0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 1024) 0           dropout_5[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 512)  2359808     dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 512 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 512 0           batch_normalization_3[0][0]      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 256 590080      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128, 128, 256 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 256 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 256 0           batch_normalization_2[0][0]      \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 128 295040      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 128 147584      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 256, 256, 128 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 512, 512, 128 0           batch_normalization_1[0][0]      \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 512, 512, 64) 256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 512, 512, 64) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 512, 512, 2)  1154        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 512, 512, 1)  3           conv2d_23[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,043,461\n",
            "Trainable params: 31,037,573\n",
            "Non-trainable params: 5,888\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "2400/2400 [==============================] - 897s 374ms/step - loss: 0.5878 - acc: 0.8934\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.58781, saving model to drive/My Drive/GAN_seg/unet.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqi1ivJw8jBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c1276f6-a54f-41aa-ac2b-80eedac12318"
      },
      "source": [
        "'''\n",
        "constructor: test\n",
        "\n",
        "path_to_testdata=             #whole path to the test image file not just folder\n",
        "path_to_outputfolder=         #folder where you want to save data\n",
        "model=                        #trained model\n",
        "COLOR_DICT=                   #colour dictionary for different classes\n",
        "image_height=512,             #height of the image. default set to 512\n",
        "image_width=512,              #width of the image. default set to 512\n",
        "image_channel=1               #number of channels of the image. default set to 1\n",
        "batch_size=15                 #batch size for testing. default set to 15\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test('<path to the test folder which includes images in the dataset>',\"<the path where you want to save the prediction outputs of the model>\",\n",
        "       trained model,colour dictionary for the classes,image_height,image_width,image_channels,batch_size)\n",
        "       <.execute> to call the main function\n",
        "'''\n",
        "\n",
        "Sky = [200,200,200]\n",
        "Building = [0,0,0]\n",
        "Pole = [192,192,128]\n",
        "Road = [128,64,128]\n",
        "Pavement = [60,40,222]\n",
        "Tree = [128,128,0]\n",
        "SignSymbol = [192,128,128]\n",
        "Fence = [64,64,128]\n",
        "Car = [64,0,128]\n",
        "Pedestrian = [64,64,0]\n",
        "Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
        "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test(path_to_testdata='drive/My Drive/GAN_seg/ADDN-master/data/img_tst.npy',path_to_outputfolder=\"drive/My Drive/GAN_seg\",\\\n",
        "     model=net,COLOR_DICT=COLOR_DICT,image_height=512,image_width=512,image_channel=1,batch_size=15).execute()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 19s 629ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}